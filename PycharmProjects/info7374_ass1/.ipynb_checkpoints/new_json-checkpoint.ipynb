{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\primary\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zaclge\\PycharmProjects\\info7374_ass1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "batch_size = 0\n",
    "num_classes = 0\n",
    "epochs = 0\n",
    "data_augmentation = True\n",
    "num_predictions = 0\n",
    "activation = \"\"\n",
    "metrics = \"\"\n",
    "\n",
    "time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "os.chdir(r'C:\\Users\\zaclge\\PycharmProjects\\info7374_ass1')\n",
    "save_dir = r'C:\\Users\\zaclge\\PycharmProjects\\info7374_ass1\\saved_models'\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "print(os.getcwd())\n",
    "def import_json(str_input):\n",
    "    \n",
    "    with open(r'C:\\Users\\zaclge\\PycharmProjects\\info7374_ass1\\configuration','r') as load_json:\n",
    "        load_dict = json.load(load_json)\n",
    "        print(load_dict)\n",
    "        global batch_size, num_classes, epochs, data_augmentation, num_predictions, activation, metrics\n",
    "        batch_size = load_dict[str_input][\"batch_size\"]\n",
    "        num_predictions = load_dict[str_input][\"num_predictions\"]\n",
    "        num_classes = load_dict[str_input][\"num_classes\"]\n",
    "        epochs = load_dict[str_input][\"epochs\"]\n",
    "        data_augmentation = load_dict[str_input][\"data_augmentation\"]\n",
    "        activation = load_dict[str_input][\"activation\"]\n",
    "        metrics = load_dict[str_input][\"metric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress(paras):\n",
    "    # The data, shuffled and split between train and test sets:\n",
    "    import_json(paras)\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    \n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    \n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[metrics])\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        model.fit(x_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  shuffle=True)\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        # This will do preprocessing and realtime data augmentation:\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "    \n",
    "        # Compute quantities required for feature-wise normalization\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(x_train)\n",
    "    \n",
    "        # Fit the model on the batches generated by datagen.flow().\n",
    "        model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                         batch_size=batch_size),\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(x_test, y_test),\n",
    "                            workers=4)\n",
    "    \n",
    "    # Save model and weights\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    model.save(model_path)\n",
    "    print('Saved trained model at %s ' % model_path)\n",
    "    \n",
    "    # Score trained model.\n",
    "    scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'one': {'batch_size': 128, 'num_classes': 10, 'epochs': 100, 'data_augmentation': True, 'num_predictions': 20, 'activation': 'relu', 'metric': 'accuracy'}, 'two': {'batch_size': 128, 'num_classes': 10, 'epochs': 100, 'data_augmentation': True, 'num_predictions': 20, 'activation': 'relu', 'metric': 'top_k_categorical_accuracy'}, 'three': {'batch_size': 128, 'num_classes': 10, 'epochs': 100, 'data_augmentation': True, 'num_predictions': 20, 'activation': 'sigmoid', 'metric': 'accuracy'}}\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 127s 325ms/step - loss: 1.9975 - acc: 0.2643 - val_loss: 1.7270 - val_acc: 0.3870\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 126s 321ms/step - loss: 1.7438 - acc: 0.3626 - val_loss: 1.5788 - val_acc: 0.4284\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 126s 322ms/step - loss: 1.6432 - acc: 0.4004 - val_loss: 1.5579 - val_acc: 0.4379\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 126s 321ms/step - loss: 1.5698 - acc: 0.4275 - val_loss: 1.4528 - val_acc: 0.4762\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 126s 323ms/step - loss: 1.5147 - acc: 0.4488 - val_loss: 1.3715 - val_acc: 0.5091\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 129s 330ms/step - loss: 1.4682 - acc: 0.4693 - val_loss: 1.3539 - val_acc: 0.5159\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 129s 330ms/step - loss: 1.4275 - acc: 0.4828 - val_loss: 1.3165 - val_acc: 0.5288\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 126s 322ms/step - loss: 1.3859 - acc: 0.4992 - val_loss: 1.2425 - val_acc: 0.5568\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 127s 326ms/step - loss: 1.3497 - acc: 0.5158 - val_loss: 1.1697 - val_acc: 0.5846\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 126s 322ms/step - loss: 1.3240 - acc: 0.5263 - val_loss: 1.2429 - val_acc: 0.5508\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 127s 324ms/step - loss: 1.2927 - acc: 0.5404 - val_loss: 1.1926 - val_acc: 0.5779\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 126s 322ms/step - loss: 1.2667 - acc: 0.5458 - val_loss: 1.1351 - val_acc: 0.5951\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 126s 321ms/step - loss: 1.2448 - acc: 0.5571 - val_loss: 1.1593 - val_acc: 0.5897\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 127s 324ms/step - loss: 1.2148 - acc: 0.5658 - val_loss: 1.0752 - val_acc: 0.6224\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 125s 321ms/step - loss: 1.1983 - acc: 0.5731 - val_loss: 1.0860 - val_acc: 0.6190\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 125s 320ms/step - loss: 1.1720 - acc: 0.5838 - val_loss: 1.0856 - val_acc: 0.6112\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 125s 320ms/step - loss: 1.1598 - acc: 0.5905 - val_loss: 1.0293 - val_acc: 0.6352\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 125s 320ms/step - loss: 1.1448 - acc: 0.5950 - val_loss: 0.9738 - val_acc: 0.6574\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 125s 320ms/step - loss: 1.1211 - acc: 0.6032 - val_loss: 0.9786 - val_acc: 0.6547\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 125s 320ms/step - loss: 1.1046 - acc: 0.6059 - val_loss: 1.0080 - val_acc: 0.6427\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 125s 320ms/step - loss: 1.0884 - acc: 0.6160 - val_loss: 0.9953 - val_acc: 0.6497\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 125s 320ms/step - loss: 1.0794 - acc: 0.6191 - val_loss: 0.9809 - val_acc: 0.6569\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 125s 320ms/step - loss: 1.0612 - acc: 0.6245 - val_loss: 0.9585 - val_acc: 0.6602\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 125s 320ms/step - loss: 1.0572 - acc: 0.6279 - val_loss: 0.9742 - val_acc: 0.6598\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 125s 321ms/step - loss: 1.0366 - acc: 0.6354 - val_loss: 0.9398 - val_acc: 0.6783\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 125s 320ms/step - loss: 1.0275 - acc: 0.6385 - val_loss: 0.9866 - val_acc: 0.6567\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 129s 329ms/step - loss: 1.0163 - acc: 0.6409 - val_loss: 0.9274 - val_acc: 0.6729\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 144s 368ms/step - loss: 1.0053 - acc: 0.6460 - val_loss: 0.8894 - val_acc: 0.6869\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 153s 391ms/step - loss: 0.9965 - acc: 0.6515 - val_loss: 0.9060 - val_acc: 0.6847\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 156s 400ms/step - loss: 0.9830 - acc: 0.6539 - val_loss: 0.8928 - val_acc: 0.6840\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 158s 404ms/step - loss: 0.9764 - acc: 0.6556 - val_loss: 0.8662 - val_acc: 0.6959\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 155s 397ms/step - loss: 0.9662 - acc: 0.6606 - val_loss: 0.8281 - val_acc: 0.7061\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 155s 397ms/step - loss: 0.9560 - acc: 0.6651 - val_loss: 0.8462 - val_acc: 0.7027\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 156s 398ms/step - loss: 0.9428 - acc: 0.6691 - val_loss: 0.8373 - val_acc: 0.7066\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 159s 406ms/step - loss: 0.9386 - acc: 0.6716 - val_loss: 0.8390 - val_acc: 0.7082\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 156s 400ms/step - loss: 0.9285 - acc: 0.6742 - val_loss: 0.8674 - val_acc: 0.6994\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 160s 408ms/step - loss: 0.9231 - acc: 0.6761 - val_loss: 0.8409 - val_acc: 0.7038\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 153s 391ms/step - loss: 0.9176 - acc: 0.6787 - val_loss: 0.8067 - val_acc: 0.7177\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 156s 398ms/step - loss: 0.9100 - acc: 0.6807 - val_loss: 0.8260 - val_acc: 0.7154\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 158s 405ms/step - loss: 0.9009 - acc: 0.6831 - val_loss: 0.8172 - val_acc: 0.7144\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 152s 389ms/step - loss: 0.8947 - acc: 0.6869 - val_loss: 0.8082 - val_acc: 0.7154\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 155s 395ms/step - loss: 0.8791 - acc: 0.6936 - val_loss: 0.7777 - val_acc: 0.7269\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 155s 397ms/step - loss: 0.8752 - acc: 0.6945 - val_loss: 0.7907 - val_acc: 0.7233\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 157s 400ms/step - loss: 0.8711 - acc: 0.6947 - val_loss: 0.7807 - val_acc: 0.7221\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 166s 424ms/step - loss: 0.8640 - acc: 0.6983 - val_loss: 0.7656 - val_acc: 0.7363\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 174s 445ms/step - loss: 0.8552 - acc: 0.7014 - val_loss: 0.7596 - val_acc: 0.7358\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 163s 417ms/step - loss: 0.8517 - acc: 0.7008 - val_loss: 0.7558 - val_acc: 0.7365\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 156s 399ms/step - loss: 0.8464 - acc: 0.7039 - val_loss: 0.7449 - val_acc: 0.7423\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 151s 387ms/step - loss: 0.8401 - acc: 0.7055 - val_loss: 0.7237 - val_acc: 0.7475\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 158s 405ms/step - loss: 0.8281 - acc: 0.7099 - val_loss: 0.7519 - val_acc: 0.7389\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 155s 396ms/step - loss: 0.8305 - acc: 0.7113 - val_loss: 0.8019 - val_acc: 0.7204\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 157s 402ms/step - loss: 0.8276 - acc: 0.7131 - val_loss: 0.7653 - val_acc: 0.7302\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 161s 413ms/step - loss: 0.8193 - acc: 0.7112 - val_loss: 0.6965 - val_acc: 0.7574\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 157s 401ms/step - loss: 0.8128 - acc: 0.7155 - val_loss: 0.7699 - val_acc: 0.7332\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 157s 401ms/step - loss: 0.8090 - acc: 0.7189 - val_loss: 0.7379 - val_acc: 0.7480\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 158s 403ms/step - loss: 0.8063 - acc: 0.7176 - val_loss: 0.7167 - val_acc: 0.7495\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 165s 422ms/step - loss: 0.8078 - acc: 0.7196 - val_loss: 0.7076 - val_acc: 0.7542\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 150s 385ms/step - loss: 0.7972 - acc: 0.7215 - val_loss: 0.6916 - val_acc: 0.7590\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 154s 395ms/step - loss: 0.7927 - acc: 0.7229 - val_loss: 0.7116 - val_acc: 0.7589\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 171s 437ms/step - loss: 0.7836 - acc: 0.7254 - val_loss: 0.6638 - val_acc: 0.7723\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 165s 423ms/step - loss: 0.7834 - acc: 0.7266 - val_loss: 0.7020 - val_acc: 0.7572\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 168s 430ms/step - loss: 0.7861 - acc: 0.7287 - val_loss: 0.7004 - val_acc: 0.7582\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 162s 414ms/step - loss: 0.7806 - acc: 0.7283 - val_loss: 0.7001 - val_acc: 0.7599\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 157s 401ms/step - loss: 0.7724 - acc: 0.7296 - val_loss: 0.6777 - val_acc: 0.7656\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 170s 435ms/step - loss: 0.7703 - acc: 0.7333 - val_loss: 0.6678 - val_acc: 0.7685\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 169s 433ms/step - loss: 0.7719 - acc: 0.7328 - val_loss: 0.6928 - val_acc: 0.7608\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 150s 385ms/step - loss: 0.7660 - acc: 0.7340 - val_loss: 0.6667 - val_acc: 0.7724\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 151s 387ms/step - loss: 0.7603 - acc: 0.7363 - val_loss: 0.6825 - val_acc: 0.7657\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 150s 385ms/step - loss: 0.7598 - acc: 0.7370 - val_loss: 0.6734 - val_acc: 0.7669\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 166s 424ms/step - loss: 0.7529 - acc: 0.7395 - val_loss: 0.6597 - val_acc: 0.7735\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 148s 378ms/step - loss: 0.7487 - acc: 0.7412 - val_loss: 0.7005 - val_acc: 0.7600\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 169s 432ms/step - loss: 0.7521 - acc: 0.7393 - val_loss: 0.6557 - val_acc: 0.7764\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 165s 421ms/step - loss: 0.7483 - acc: 0.7411 - val_loss: 0.6787 - val_acc: 0.7648\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 161s 412ms/step - loss: 0.7471 - acc: 0.7411 - val_loss: 0.6508 - val_acc: 0.7762\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 149s 380ms/step - loss: 0.7386 - acc: 0.7438 - val_loss: 0.6376 - val_acc: 0.7810\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 136s 349ms/step - loss: 0.7328 - acc: 0.7457 - val_loss: 0.6387 - val_acc: 0.7804\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 136s 349ms/step - loss: 0.7338 - acc: 0.7465 - val_loss: 0.6678 - val_acc: 0.7701\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 136s 348ms/step - loss: 0.7334 - acc: 0.7455 - val_loss: 0.6137 - val_acc: 0.7890\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 136s 349ms/step - loss: 0.7305 - acc: 0.7477 - val_loss: 0.6425 - val_acc: 0.7800\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 136s 348ms/step - loss: 0.7204 - acc: 0.7512 - val_loss: 0.6504 - val_acc: 0.7737\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 136s 348ms/step - loss: 0.7315 - acc: 0.7456 - val_loss: 0.6307 - val_acc: 0.7858\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 136s 348ms/step - loss: 0.7250 - acc: 0.7497 - val_loss: 0.6477 - val_acc: 0.7797\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 136s 347ms/step - loss: 0.7236 - acc: 0.7496 - val_loss: 0.6714 - val_acc: 0.7755\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 136s 347ms/step - loss: 0.7193 - acc: 0.7514 - val_loss: 0.6279 - val_acc: 0.7838\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 136s 348ms/step - loss: 0.7182 - acc: 0.7533 - val_loss: 0.6455 - val_acc: 0.7816\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 136s 347ms/step - loss: 0.7163 - acc: 0.7535 - val_loss: 0.6216 - val_acc: 0.7889\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 136s 347ms/step - loss: 0.7136 - acc: 0.7543 - val_loss: 0.6263 - val_acc: 0.7846\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 136s 347ms/step - loss: 0.7143 - acc: 0.7526 - val_loss: 0.6465 - val_acc: 0.7777\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 136s 347ms/step - loss: 0.7087 - acc: 0.7565 - val_loss: 0.6446 - val_acc: 0.7804\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 136s 347ms/step - loss: 0.7089 - acc: 0.7564 - val_loss: 0.6398 - val_acc: 0.7807\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 136s 348ms/step - loss: 0.7060 - acc: 0.7580 - val_loss: 0.6708 - val_acc: 0.7705\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 136s 347ms/step - loss: 0.7076 - acc: 0.7566 - val_loss: 0.6079 - val_acc: 0.7928\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 136s 348ms/step - loss: 0.7067 - acc: 0.7581 - val_loss: 0.6060 - val_acc: 0.7973\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 136s 348ms/step - loss: 0.7005 - acc: 0.7600 - val_loss: 0.6461 - val_acc: 0.7815\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 136s 347ms/step - loss: 0.7015 - acc: 0.7606 - val_loss: 0.6060 - val_acc: 0.7943\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 136s 347ms/step - loss: 0.7022 - acc: 0.7575 - val_loss: 0.6321 - val_acc: 0.7827\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 136s 347ms/step - loss: 0.6987 - acc: 0.7591 - val_loss: 0.6204 - val_acc: 0.7883\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 136s 349ms/step - loss: 0.7004 - acc: 0.7592 - val_loss: 0.6216 - val_acc: 0.7923\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 136s 347ms/step - loss: 0.6957 - acc: 0.7614 - val_loss: 0.6206 - val_acc: 0.7902\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 136s 347ms/step - loss: 0.6911 - acc: 0.7637 - val_loss: 0.6536 - val_acc: 0.7781\n",
      "Saved trained model at C:\\Users\\zaclge\\PycharmProjects\\info7374_ass1\\saved_models\\keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 9s 871us/step\n",
      "Test loss: 0.6536137211799622\n",
      "Test accuracy: 0.7781\n"
     ]
    }
   ],
   "source": [
    "progress(\"one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/zacgle007/Desktop/info7374_ass1/configuration'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-07e14c47eb17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprogress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"two\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-9769d22660e0>\u001b[0m in \u001b[0;36mprogress\u001b[1;34m(paras)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# The data, shuffled and split between train and test sets:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mimport_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x_train shape:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-918014184474>\u001b[0m in \u001b[0;36mimport_json\u001b[1;34m(str_input)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimport_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'/Users/zacgle007/Desktop/info7374_ass1/configuration'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mload_json\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mload_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/zacgle007/Desktop/info7374_ass1/configuration'"
     ]
    }
   ],
   "source": [
    "progress(\"two\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'one': {'batch_size': 128, 'num_classes': 10, 'epochs': 100, 'data_augmentation': True, 'num_predictions': 20, 'activation': 'relu', 'metric': 'accuracy'}, 'two': {'batch_size': 32, 'num_classes': 10, 'epochs': 100, 'data_augmentation': True, 'num_predictions': 20, 'activation': 'relu', 'metric': 'top_k_categorical_accuracy'}, 'three': {'batch_size': 32, 'num_classes': 10, 'epochs': 100, 'data_augmentation': True, 'num_predictions': 20, 'activation': 'sigmoid', 'metric': 'accuracy'}}\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 336s 215ms/step - loss: 2.3311 - acc: 0.1006 - val_loss: 2.3046 - val_acc: 0.1000\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 335s 214ms/step - loss: 2.3072 - acc: 0.1004 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 333s 213ms/step - loss: 2.3063 - acc: 0.1006 - val_loss: 2.3036 - val_acc: 0.1000\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 333s 213ms/step - loss: 2.3056 - acc: 0.1027 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 327s 209ms/step - loss: 2.3052 - acc: 0.1021 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 2.3049 - acc: 0.1029 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 320s 204ms/step - loss: 2.3043 - acc: 0.0994 - val_loss: 2.3014 - val_acc: 0.1000\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 2.1975 - acc: 0.1726 - val_loss: 2.0387 - val_acc: 0.2571\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 2.0561 - acc: 0.2460 - val_loss: 1.9704 - val_acc: 0.2866\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 2.0094 - acc: 0.2635 - val_loss: 1.9231 - val_acc: 0.3075\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.9787 - acc: 0.2729 - val_loss: 1.8920 - val_acc: 0.3097\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 1.9519 - acc: 0.2836 - val_loss: 1.8675 - val_acc: 0.3198\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 321s 206ms/step - loss: 1.9375 - acc: 0.2906 - val_loss: 1.8392 - val_acc: 0.3417\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.9202 - acc: 0.2970 - val_loss: 1.8240 - val_acc: 0.3446\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 1.9075 - acc: 0.3034 - val_loss: 1.8092 - val_acc: 0.3447\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.8936 - acc: 0.3103 - val_loss: 1.7887 - val_acc: 0.3530\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 318s 203ms/step - loss: 1.8781 - acc: 0.3167 - val_loss: 1.7701 - val_acc: 0.3648\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.8664 - acc: 0.3202 - val_loss: 1.7803 - val_acc: 0.3542\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 318s 203ms/step - loss: 1.8535 - acc: 0.3232 - val_loss: 1.7366 - val_acc: 0.3715\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.8424 - acc: 0.3283 - val_loss: 1.7219 - val_acc: 0.3780\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 1.8297 - acc: 0.3302 - val_loss: 1.7007 - val_acc: 0.3822\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.8172 - acc: 0.3380 - val_loss: 1.7231 - val_acc: 0.3852\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.8069 - acc: 0.3387 - val_loss: 1.6765 - val_acc: 0.3930\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.7884 - acc: 0.3501 - val_loss: 1.6623 - val_acc: 0.4045\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.7805 - acc: 0.3526 - val_loss: 1.6423 - val_acc: 0.4105\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.7649 - acc: 0.3586 - val_loss: 1.6210 - val_acc: 0.4211\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.7494 - acc: 0.3639 - val_loss: 1.6067 - val_acc: 0.4183\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 321s 206ms/step - loss: 1.7336 - acc: 0.3680 - val_loss: 1.5870 - val_acc: 0.4317\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.7186 - acc: 0.3717 - val_loss: 1.5786 - val_acc: 0.4334\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.7096 - acc: 0.3801 - val_loss: 1.5573 - val_acc: 0.4365\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 324s 207ms/step - loss: 1.6976 - acc: 0.3842 - val_loss: 1.5451 - val_acc: 0.4449\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 1.6787 - acc: 0.3887 - val_loss: 1.5388 - val_acc: 0.4435\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 318s 204ms/step - loss: 1.6667 - acc: 0.3938 - val_loss: 1.5199 - val_acc: 0.4474\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.6604 - acc: 0.3925 - val_loss: 1.4967 - val_acc: 0.4603\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.6481 - acc: 0.4061 - val_loss: 1.5032 - val_acc: 0.4569\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 1.6345 - acc: 0.4081 - val_loss: 1.4905 - val_acc: 0.4609\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.6234 - acc: 0.4093 - val_loss: 1.4710 - val_acc: 0.4713\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.6178 - acc: 0.4143 - val_loss: 1.4670 - val_acc: 0.4742\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.6055 - acc: 0.4206 - val_loss: 1.4609 - val_acc: 0.4738\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.5910 - acc: 0.4248 - val_loss: 1.4434 - val_acc: 0.4842\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 1.5832 - acc: 0.4266 - val_loss: 1.4472 - val_acc: 0.4828\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.5737 - acc: 0.4350 - val_loss: 1.4179 - val_acc: 0.4890\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.5744 - acc: 0.4315 - val_loss: 1.4163 - val_acc: 0.4931\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.5613 - acc: 0.4385 - val_loss: 1.4075 - val_acc: 0.4980\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.5564 - acc: 0.4392 - val_loss: 1.3992 - val_acc: 0.4998\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.5497 - acc: 0.4431 - val_loss: 1.3979 - val_acc: 0.4967\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 321s 206ms/step - loss: 1.5418 - acc: 0.4461 - val_loss: 1.3855 - val_acc: 0.5008\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 1.5412 - acc: 0.4463 - val_loss: 1.3901 - val_acc: 0.5016\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.5367 - acc: 0.4477 - val_loss: 1.3983 - val_acc: 0.4999\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 320s 204ms/step - loss: 1.5291 - acc: 0.4521 - val_loss: 1.3800 - val_acc: 0.5045\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 323s 206ms/step - loss: 1.5258 - acc: 0.4517 - val_loss: 1.3689 - val_acc: 0.5116\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.5225 - acc: 0.4549 - val_loss: 1.3638 - val_acc: 0.5138\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.5160 - acc: 0.4584 - val_loss: 1.3609 - val_acc: 0.5154\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.5126 - acc: 0.4579 - val_loss: 1.3608 - val_acc: 0.5157\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 1.5098 - acc: 0.4610 - val_loss: 1.3536 - val_acc: 0.5135\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.5077 - acc: 0.4598 - val_loss: 1.3584 - val_acc: 0.5150\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 1.5056 - acc: 0.4611 - val_loss: 1.3444 - val_acc: 0.5209\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 320s 204ms/step - loss: 1.4999 - acc: 0.4633 - val_loss: 1.3371 - val_acc: 0.5237\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.4981 - acc: 0.4640 - val_loss: 1.3374 - val_acc: 0.5239\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.4996 - acc: 0.4634 - val_loss: 1.3308 - val_acc: 0.5244\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.4918 - acc: 0.4678 - val_loss: 1.3284 - val_acc: 0.5265\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.4881 - acc: 0.4671 - val_loss: 1.3344 - val_acc: 0.5253\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 1.4876 - acc: 0.4706 - val_loss: 1.3264 - val_acc: 0.5219\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.4875 - acc: 0.4699 - val_loss: 1.3189 - val_acc: 0.5291\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 324s 207ms/step - loss: 1.4784 - acc: 0.4718 - val_loss: 1.3165 - val_acc: 0.5314\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.4810 - acc: 0.4696 - val_loss: 1.3248 - val_acc: 0.5257\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.4738 - acc: 0.4721 - val_loss: 1.3287 - val_acc: 0.5327\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.4741 - acc: 0.4725 - val_loss: 1.3030 - val_acc: 0.5347\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.4716 - acc: 0.4732 - val_loss: 1.3213 - val_acc: 0.5350\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.4689 - acc: 0.4728 - val_loss: 1.2975 - val_acc: 0.5422\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 321s 206ms/step - loss: 1.4653 - acc: 0.4766 - val_loss: 1.3040 - val_acc: 0.5383\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 321s 206ms/step - loss: 1.4649 - acc: 0.4768 - val_loss: 1.2919 - val_acc: 0.5375\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.4609 - acc: 0.4790 - val_loss: 1.3018 - val_acc: 0.5312\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.4576 - acc: 0.4792 - val_loss: 1.2921 - val_acc: 0.5410\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.4571 - acc: 0.4779 - val_loss: 1.2869 - val_acc: 0.5388\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.4518 - acc: 0.4776 - val_loss: 1.2850 - val_acc: 0.5459\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.4506 - acc: 0.4827 - val_loss: 1.3024 - val_acc: 0.5318\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.4518 - acc: 0.4834 - val_loss: 1.2699 - val_acc: 0.5463\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 323s 207ms/step - loss: 1.4494 - acc: 0.4809 - val_loss: 1.2733 - val_acc: 0.5517\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 321s 206ms/step - loss: 1.4440 - acc: 0.4833 - val_loss: 1.2712 - val_acc: 0.5465\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.4456 - acc: 0.4845 - val_loss: 1.2804 - val_acc: 0.5478\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 321s 206ms/step - loss: 1.4393 - acc: 0.4860 - val_loss: 1.2769 - val_acc: 0.5471\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.4363 - acc: 0.4852 - val_loss: 1.2614 - val_acc: 0.5564\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.4349 - acc: 0.4863 - val_loss: 1.2610 - val_acc: 0.5587\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.4340 - acc: 0.4861 - val_loss: 1.2524 - val_acc: 0.5525\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 1.4320 - acc: 0.4906 - val_loss: 1.2581 - val_acc: 0.5544\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 320s 205ms/step - loss: 1.4320 - acc: 0.4877 - val_loss: 1.2510 - val_acc: 0.5586\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.4244 - acc: 0.4904 - val_loss: 1.2475 - val_acc: 0.5614\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 320s 204ms/step - loss: 1.4270 - acc: 0.4922 - val_loss: 1.2546 - val_acc: 0.5616\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.4199 - acc: 0.4949 - val_loss: 1.2444 - val_acc: 0.5581\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 327s 209ms/step - loss: 1.4181 - acc: 0.4961 - val_loss: 1.2374 - val_acc: 0.5595\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 323s 207ms/step - loss: 1.4187 - acc: 0.4933 - val_loss: 1.2432 - val_acc: 0.5654\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.4171 - acc: 0.4926 - val_loss: 1.2364 - val_acc: 0.5635\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 325s 208ms/step - loss: 1.4099 - acc: 0.4978 - val_loss: 1.2325 - val_acc: 0.5619\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 321s 205ms/step - loss: 1.4101 - acc: 0.4964 - val_loss: 1.2383 - val_acc: 0.5586\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.4057 - acc: 0.4980 - val_loss: 1.2386 - val_acc: 0.5662\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 323s 207ms/step - loss: 1.4074 - acc: 0.4975 - val_loss: 1.2298 - val_acc: 0.5631\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 324s 207ms/step - loss: 1.4037 - acc: 0.4995 - val_loss: 1.2327 - val_acc: 0.5642\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.4015 - acc: 0.5008 - val_loss: 1.2200 - val_acc: 0.5664\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.4007 - acc: 0.4992 - val_loss: 1.2308 - val_acc: 0.5681\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "`save_model` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8b45a48afa78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprogress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"three\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-9769d22660e0>\u001b[0m in \u001b[0;36mprogress\u001b[0;34m(paras)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saved trained model at %s '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/primary/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   2574\u001b[0m         \"\"\"\n\u001b[1;32m   2575\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/primary/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_model` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_json_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_model` requires h5py."
     ]
    }
   ],
   "source": [
    "progress(\"three\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
